{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LLMs to Generate NIH Data Management Plans (DMPs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama  # Local LLMs like Llama3 \n",
    "import openai  # GPT-4 API\n",
    "import pypandoc  # Convert Markdown to DOCX\n",
    "import pandas as pd  # Handle structured data\n",
    "import os  # File handling\n",
    "from dotenv import load_dotenv  # Load API keys securely\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Set API keys\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Functions\n",
    "\n",
    "**Function 1**  Query LLaMA 3.3 (Ollama - Local Models)\n",
    "This function is responsible for sending prompts to locally hosted LLaMA 3 model using the Ollama interface and retrieving responses.\n",
    "\n",
    "**Function 2**  Query Open AI\n",
    "This function is responsible for sending prompts to GPT\n",
    "\n",
    "**Function 3** Create a Directory if it Doesn't Exist\n",
    "Ensures that a specified directory exists. If it does not, the function creates it.\n",
    "\n",
    "**Function 4** Save Markdown Files\n",
    "Saves the generated text content into a `.md` (Markdown) file format for documentation or further processing.\n",
    "\n",
    "**Function 5**  Convert Markdown to DOCX\n",
    "Takes markdown-formatted content and converts it into a `.docx` Word document, enabling easy viewing and sharing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Function1:Query Llama 3 & DeepSeek (Ollama - Local Models)\n",
    "def ask_llm_ollama(model, query):\n",
    "    \"\"\"\n",
    "    Queries an LLM model via Ollama (local models).\n",
    "\n",
    "    Args:\n",
    "        model (str): Name of the model in Ollama (must be installed locally).\n",
    "        query (str): Query string to send to the model.\n",
    "\n",
    "    Returns:\n",
    "        str: Response from the LLM.\n",
    "    \"\"\"\n",
    "    response = ollama.chat(model=model, messages=[{\"role\": \"user\", \"content\": query}])\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function 2: Querying the LLM via OpenAI API\n",
    "import openai\n",
    "\n",
    "def ask_llm_openai(model, query):\n",
    "    \"\"\"\n",
    "    Queries an LLM model via OpenAI API and returns the response.\n",
    "\n",
    "    Args:\n",
    "        model (str): Name of the OpenAI model (e.g., \"gpt-4-turbo\").\n",
    "        query (str): Query string to send to the model.\n",
    "\n",
    "    Returns:\n",
    "        str: Response from the OpenAI model.\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI()  \n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": query}],\n",
    "        temperature=0.7  \n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function3 : Create a Directory if it Doesn't Exist\n",
    "def create_folder(folderpath):\n",
    "    \"\"\"\n",
    "    Creates a folder at the specified path if it doesn't already exist.\n",
    "\n",
    "    Args:\n",
    "        folderpath (str): The path of the folder to create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folderpath):\n",
    "        os.makedirs(folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function4: Save Markdown Files\n",
    "def save_md(folderpath, filename, response):\n",
    "    \"\"\"\n",
    "    Saves a given response as a Markdown (.md) file.\n",
    "\n",
    "    Args:\n",
    "        folderpath (str): Path where the file should be saved.\n",
    "        filename (str): Name of the Markdown file.\n",
    "        response (str): The text to be saved.\n",
    "    \"\"\"\n",
    "    create_folder(folderpath)  \n",
    "    filepath = os.path.join(folderpath, filename) \n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(response)  \n",
    "    print(filepath, \"saved\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function5 : Convert Markdown to DOCX\n",
    "def md_to_docs(md_filepath, docx_folderpath, docx_filename):\n",
    "    \"\"\"\n",
    "    Converts a Markdown file to a Word (.docx) document using pypandoc.\n",
    "\n",
    "    Args:\n",
    "        md_filepath (str): Path to the source Markdown file.\n",
    "        docx_folderpath (str): Path where the DOCX file will be saved.\n",
    "        docx_filename (str): Name of the DOCX file.\n",
    "    \"\"\"\n",
    "    create_folder(docx_folderpath)  \n",
    "    docx_filepath = os.path.join(docx_folderpath, docx_filename)  \n",
    "    pypandoc.convert_file(md_filepath, 'docx', outputfile=docx_filepath)  \n",
    "    print(docx_filepath, \"saved\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: Load Input Files\n",
    "\n",
    "In this step, the script defines paths for input files and loads them into memory:\n",
    "\n",
    "- **Excel File**: Contains the structured DMP data to be processed.\n",
    "- **Markdown Template**: Serves as the base template for generating customized DMP content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Excel file loaded successfully!\n",
      " DMP template loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define file paths\n",
    "import os\n",
    "import pandas as pd\n",
    "excel_path = \"inputs/inputs.xlsx\"\n",
    "template_path = \"inputs/dmp-template.md\"\n",
    "\n",
    "# Check and load Excel data\n",
    "if os.path.exists(excel_path):\n",
    "    df = pd.read_excel(excel_path)\n",
    "    print(\" Excel file loaded successfully!\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\" Error: The file '{excel_path}' was not found.\")\n",
    "\n",
    "# Check and load Markdown template\n",
    "if os.path.exists(template_path):\n",
    "    with open(template_path, 'r', encoding='utf-8') as file:\n",
    "        dmp_template_text = file.read()\n",
    "    print(\" DMP template loaded successfully!\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\" Error: The file '{template_path}' was not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate Model Outputs for NIH DMPs Using GPT and LLaMA\n",
    "\n",
    "This step generates Data Management and Sharing Plans (DMSPs) using both OpenAI (GPT-4.1) and Ollama (LLaMA3.3) in a **single run**. Each model receives a customized prompt generated from structured metadata.\n",
    "\n",
    "###  Inputs\n",
    "\n",
    "- `df`: DataFrame containing DMP sample metadata (e.g., title, institute, human study flag, element_1A).\n",
    "- `dmp_template_text`: The official NIH markdown-formatted DMP template.\n",
    "- Model lists:\n",
    "  - `openai_models = [\"gpt-4.1\"]`\n",
    "  - `ollama_models = [\"llama3.3\"]`\n",
    "\n",
    "### Query Generation\n",
    "\n",
    "- A detailed, context-aware query is created for each DMP using:\n",
    "  - Targeted funding agency\n",
    "  - Project-specific data collection (element 1A)\n",
    "  - Human participant considerations (if applicable)\n",
    "  - Fixed NIH-compliant markdown structure\n",
    "\n",
    "The final query is stored in the `Generated Query` column and saved to `outputs/with_generated_queries.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Prompting (Single Run)\n",
    "\n",
    "- A clean folder structure is created:\n",
    "  - `outputs/Gpt_result/approach1_outputs_Gpt/`\n",
    "  - `outputs/Llama_result/approach1_outputs_Llama/`\n",
    "\n",
    "- Each DMP is processed using the generated query:\n",
    "  - **Input query saved as `.docx` for traceability**\n",
    "  - **Model output saved as `.md` (markdown)**\n",
    "  - Markdown files are converted to `.docx` for review.\n",
    "\n",
    "---\n",
    "\n",
    "### Output Artifacts\n",
    "\n",
    "For each DMP:\n",
    "- Input query saved as: `DMP_Title_query.docx`\n",
    "- Model outputs saved as:\n",
    "  - `openai-gpt-4.1.md` / `.docx`\n",
    "  - `ollama-llama3.3.md` / `.docx`\n",
    "\n",
    "This setup keeps the generation process simple, repeatable, and fully traceable, supporting downstream evaluation and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of LLM models to be used (Ollama & OpenAI)\n",
    "import ollama\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from docx import Document\n",
    "ollama_models = [\"llama3.3\"]\n",
    "openai_models = [\"gpt-4.1\"]\n",
    "\n",
    "\n",
    "# Initial query template for NIH Data Management and Sharing Plan (DMP)\n",
    "query_initiate = \"You are an expert biomedical grant writer and data steward. Create a Data Management and Sharing Plan (DMSP) for a grant proposal being submitted to the National Institutes of Health (NIH), \"\n",
    "\n",
    "# Query format using the NIH template\n",
    "query_template = \"Provide the result using exactly this markdown format template of the DMSP provided by the NIH without changing it (keep all the titles and sections as is) to give me a well-formatted markdown output that follows the NIH-required format:\" + dmp_template_text\n",
    "\n",
    "# Function to generate query from a row\n",
    "def generate_query(row):\n",
    "\n",
    "    query_funding_agency = f\"Specifically targeting the {row['institute']}.\"\n",
    "    query_Element1_A = (\n",
    "        f\"Here are the details about the data to be collected:\\n\"\n",
    "        f\"{row['element_1A']}\\n\"\n",
    "    )\n",
    "\n",
    "    if \"yes\" in str(row['isHumanStudy']).lower():\n",
    "        query_consent_type = (\n",
    "            f\"This proposal includes a study that will involve human participants. {row['consentDescription']}.\"\n",
    "        )\n",
    "    else:\n",
    "        query_consent_type = \"\"\n",
    "\n",
    "    # Combine into final query\n",
    "    query = \" \".join([\n",
    "        #query_dmp,\n",
    "        query_initiate,\n",
    "        query_funding_agency,\n",
    "        query_Element1_A,\n",
    "        query_consent_type,\n",
    "        query_template\n",
    "    ])\n",
    "    \n",
    "    return query\n",
    "\n",
    "\n",
    "# Apply the function to each row and store in a new column\n",
    "df[\"Generated Query\"] = df.apply(generate_query, axis=1)\n",
    "df.to_csv(\"outputs/with_generated_queries.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Single run started...\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Clinical and MRI data from human research participants\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Clinical and MRI data from human research participants\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Clinical and MRI data from human research participants\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Clinical and MRI data from human research participants\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Genomic data from human research participants\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Genomic data from human research participants\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Genomic data from human research participants\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Genomic data from human research participants\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Genomic data from a non-human source\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Genomic data from a non-human source\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Genomic data from a non-human source\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Genomic data from a non-human source\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Secondary data analysis\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Secondary data analysis\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Secondary data analysis\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Secondary data analysis\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Human clinical and genomics data\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Human clinical and genomics data\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Human clinical and genomics data\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Human clinical and genomics data\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Gene expression analysis data from non-human model organism (zebrafish)\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Gene expression analysis data from non-human model organism (zebrafish)\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Gene expression analysis data from non-human model organism (zebrafish)\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Gene expression analysis data from non-human model organism (zebrafish)\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Human survey data\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Human survey data\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Human survey data\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Human survey data\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Clinical Data from Human Research Participants\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Clinical Data from Human Research Participants\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Clinical Data from Human Research Participants\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Clinical Data from Human Research Participants\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Human genomic data\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Human genomic data\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Human genomic data\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Human genomic data\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Technology development\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Technology development\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Technology development\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Technology development\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Basic Research from a Non-Human Source Example\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Basic Research from a Non-Human Source Example\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Basic Research from a Non-Human Source Example\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Basic Research from a Non-Human Source Example\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Secondary Data Analysis Example\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Secondary Data Analysis Example\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Secondary Data Analysis Example\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Secondary Data Analysis Example\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Survey and Interview Example\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Survey and Interview Example\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Survey and Interview Example\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Survey and Interview Example\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Human Clinical Trial Data\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Human Clinical Trial Data\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Human Clinical Trial Data\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Human Clinical Trial Data\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Clinical data from human research participants-NIA\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Clinical data from human research participants-NIA\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Clinical data from human research participants-NIA\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Clinical data from human research participants-NIA\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Survey, interview, and biological data (tiered access)\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Survey, interview, and biological data (tiered access)\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Survey, interview, and biological data (tiered access)\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Survey, interview, and biological data (tiered access)\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Non-human data (primates)\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Non-human data (primates)\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Non-human data (primates)\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Non-human data (primates)\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Secondary data analysis-NIA\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Secondary data analysis-NIA\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Secondary data analysis-NIA\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Secondary data analysis-NIA\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Survey and interview data-NIA\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Survey and interview data-NIA\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Survey and interview data-NIA\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Survey and interview data-NIA\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Human clinical and genomic data-NIA\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Human clinical and genomic data-NIA\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Human clinical and genomic data-NIA\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Human clinical and genomic data-NIA\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Non-human data (rodents)-NIA\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Non-human data (rodents)-NIA\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Non-human data (rodents)-NIA\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Non-human data (rodents)-NIA\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Clinical data (human biospecimens)\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Clinical data (human biospecimens)\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Clinical data (human biospecimens)\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Clinical data (human biospecimens)\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Drug discovery including intellectual property\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Drug discovery including intellectual property\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Drug discovery including intellectual property\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Drug discovery including intellectual property\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\HeLa Cell Whole Genome Sequence (DNA or RNA)\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\HeLa Cell Whole Genome Sequence (DNA or RNA)\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\HeLa Cell Whole Genome Sequence (DNA or RNA)\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\HeLa Cell Whole Genome Sequence (DNA or RNA)\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Secondary Data Analysis on Data from Human Subjects-NIA\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Secondary Data Analysis on Data from Human Subjects-NIA\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Secondary Data Analysis on Data from Human Subjects-NIA\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Secondary Data Analysis on Data from Human Subjects-NIA\\ollama-llama3.3.docx saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Analysis of social media posts\\openai-gpt-4.1.md saved\n",
      "outputs/Gpt_result/approach1_outputs_Gpt\\Analysis of social media posts\\openai-gpt-4.1.docx saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Analysis of social media posts\\ollama-llama3.3.md saved\n",
      "outputs/Llama_result/approach1_outputs_Llama\\Analysis of social media posts\\ollama-llama3.3.docx saved\n",
      " Single run completed. Results are saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "\n",
    "# Utility\n",
    "def clean_filename(name: str) -> str:\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", str(name).strip())\n",
    "\n",
    "\n",
    "def save_query_doc(folderpath: str, name: str, query: str) -> None:\n",
    "    doc = Document()\n",
    "    doc.add_heading(\"Generated DMP Query\", level=1)\n",
    "    doc.add_paragraph(query)\n",
    "    doc.save(os.path.join(folderpath, f\"{name}_query.docx\"))\n",
    "\n",
    "\n",
    "def process_models(\n",
    "    models,\n",
    "    query_func,\n",
    "    model_prefix: str,\n",
    "    base_folder: str,\n",
    "    query: str,\n",
    "    dmp_name_clean: str\n",
    ") -> None:\n",
    "    folderpath = os.path.join(base_folder, dmp_name_clean)\n",
    "    os.makedirs(folderpath, exist_ok=True)\n",
    "\n",
    "    # Save the input query once per DMP (per model family folder)\n",
    "    save_query_doc(folderpath, dmp_name_clean, query)\n",
    "\n",
    "    for model in models:\n",
    "        response = query_func(model, query)\n",
    "        modelname = model.replace(\":\", \"-\")\n",
    "        filename_md = f\"{model_prefix}-{modelname}.md\"\n",
    "        filename_docx = filename_md.replace(\".md\", \".docx\")\n",
    "\n",
    "        save_md(folderpath, filename_md, response)\n",
    "        md_to_docs(\n",
    "            os.path.join(folderpath, filename_md),\n",
    "            folderpath,\n",
    "            filename_docx\n",
    "        )\n",
    "\n",
    "\n",
    "# Single Run Generation\n",
    "\n",
    "print(\" Single run started...\")\n",
    "\n",
    "# Output base folders (single run)\n",
    "output_base_openai = \"outputs/Gpt_result/approach1_outputs_Gpt\"\n",
    "output_base_ollama = \"outputs/Llama_result/approach1_outputs_Llama\"\n",
    "os.makedirs(output_base_openai, exist_ok=True)\n",
    "os.makedirs(output_base_ollama, exist_ok=True)\n",
    "\n",
    "# Loop through DataFrame and process\n",
    "for _, row in df.iterrows():\n",
    "    query = row[\"Generated Query\"]\n",
    "    dmp_name_clean = clean_filename(row.get(\"title\", \"untitled_dmp\"))\n",
    "\n",
    "    # Process OpenAI models\n",
    "    process_models(openai_models, ask_llm_openai, \"openai\", output_base_openai, query, dmp_name_clean)\n",
    "\n",
    "    # Process Ollama models\n",
    "    process_models(ollama_models, ask_llm_ollama, \"ollama\", output_base_ollama, query, dmp_name_clean)\n",
    "\n",
    "print(\" Single run completed. Results are saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
